{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object to hold all property result\n",
    "list_result = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the URL you want to webscrape from\n",
    "url = 'http://www.singapore.pl/i_singapore_condominium_and_private_project_list.jsp?cblg=0..9'\n",
    "\n",
    "# Connect to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse HTML and save to BeautifulSoup object¶\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_directory = []\n",
    "\n",
    "# To download the whole data set, let's do a for loop through all a tags\n",
    "for one_a_tag in soup.findAll('a'):  #'a' tags are for links\n",
    "    link = one_a_tag['href']\n",
    "    if ('i_singapore_condominium_and_private_project_list.jsp?cblg=' in link):\n",
    "        print(link)\n",
    "        list_directory.append('http://www.singapore.pl/' + link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retreieve the individual URL of each property\n",
    "list_property_url = []\n",
    "\n",
    "for url in list_directory[:]:\n",
    "    # Connect to the URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Parse HTML and save to BeautifulSoup object¶\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "    # To download the whole data set, let's do a for loop through all a tags\n",
    "    for one_a_tag in soup.findAll('a'):  #'a' tags are for links\n",
    "        link = one_a_tag['href']\n",
    "        if ('http://www.data.com.sg/property/mainproj.fxp?cid=singapore' in link):\n",
    "            list_property_url.append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_property_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeSpace(str):\n",
    "    try:\n",
    "        return str.strip()\n",
    "    except:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_property_url[3544]\n",
    "for url in list_property_url[3545:3546]:\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in list_property_url[3544:3555]:\n",
    "    try:\n",
    "        # Connect to the URL\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # Parse HTML and save to BeautifulSoup object¶\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        list_property = soup.findAll('td')\n",
    "        dict_res = {}\n",
    "        dict_res['Property Name'] = removeSpace(soup.findAll('h2')[1].string)\n",
    "        dict_res['Property Type'] = removeSpace(list_property[1].string)\n",
    "        dict_res['Developer Name'] = removeSpace(list_property[3].string)\n",
    "        dict_res['Road Name'] = removeSpace(list_property[5].string)\n",
    "        dict_res['Tenure Type'] = removeSpace(list_property[7].string)\n",
    "        dict_res['TOP Date'] = removeSpace(list_property[9].string)\n",
    "        dict_res['District Code'] = removeSpace(list_property[11].string)\n",
    "        dict_res['Postal Code'] = removeSpace(list_property[13].string)\n",
    "\n",
    "        list_result.append(dict_res)\n",
    "    except:\n",
    "        print(\"Error: \" + url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(list_result)\n",
    "\n",
    "writer = pd.ExcelWriter('Data\\Commercial Property Info.xlsx')\n",
    "result.to_excel(writer) \n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
